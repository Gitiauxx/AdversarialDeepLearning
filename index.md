---
layout: post
title:  "Adversarial Deep Learning"
---

# Adversarial Deep Learning
Adversarial learning generates applies small perturbations to 
the inputs of a deep learning architecture so that the neural network
outputs a wrong answer with high confidence. 


**Why does it matter?**
The lack of robustness to small perturbation is seen as a sign that 
neural networks do not learn the true data manifold and 

Adversarial examples are input to trick the neural network. 
Changes are imperceptible to human perception. 
Here attacks are white box attacks with access to model parameters.